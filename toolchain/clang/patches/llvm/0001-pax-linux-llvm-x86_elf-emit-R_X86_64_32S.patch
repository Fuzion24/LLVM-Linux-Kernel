#[21:38:01] <pipacs> that's a correctness fix, it's not adding new opcodes
#           but enforces a certain relocation type for some additional 
#           insns that need it
#[21:39:11] <pipacs> now it's probably not the optimal implementation 
#           but i couldn't find a way to get the needed metadata out 
#           of llvm to reduce the big if into a few conditionals
From 666bfad7055f0cfad8608f27898bab150df1edbc Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Jan-Simon=20M=C3=B6ller?= <dl9pf@gmx.de>
Date: Tue, 10 Jul 2012 12:35:25 +0200
Subject: [PATCH 1/6] pax-linux-llvm x86_elf-emit-R_X86_64_32S.patch
 Patch from series at http://lists.cs.uiuc.edu/pipermail/llvm-commits/Week-of-Mon-20120507/142707.html by PaX Team.

---
 lib/Target/X86/MCTargetDesc/X86MCCodeEmitter.cpp |   40 +++++++++++++++++++--
 1 files changed, 36 insertions(+), 4 deletions(-)

Index: llvm/lib/Target/X86/MCTargetDesc/X86MCCodeEmitter.cpp
===================================================================
--- llvm.orig/lib/Target/X86/MCTargetDesc/X86MCCodeEmitter.cpp	2012-07-20 12:45:59.054750510 -0400
+++ llvm/lib/Target/X86/MCTargetDesc/X86MCCodeEmitter.cpp	2012-07-20 15:19:25.152993803 -0400
@@ -1195,10 +1195,42 @@
     } else {
       unsigned FixupKind;
       // FIXME: Is there a better way to know that we need a signed relocation?
-      if (MI.getOpcode() == X86::ADD64ri32 ||
-          MI.getOpcode() == X86::MOV64ri32 ||
-          MI.getOpcode() == X86::MOV64mi32 ||
-          MI.getOpcode() == X86::PUSH64i32)
+//      if (is64BitMode() && X86II::getSizeOfImm(TSFlags) == 4 &&
+//          ((MemoryOperand != -1 && Is64BitMemOperand(MI, MemoryOperand)) ||
+//           (<check for 64 bit register operand>)))
+//grep "^  {.*ImmSExti64i32" lib/Target/X86/X86GenAsmMatcher.inc | awk '{print $6}' | sort -u | sed -e 's/\(.*\),/            MI.getOpcode() == \1 ||/'
+       if (MI.getOpcode() == X86::ADC64i32 ||
+           MI.getOpcode() == X86::ADC64mi32 ||
+           MI.getOpcode() == X86::ADC64ri32 ||
+           MI.getOpcode() == X86::ADD64i32 ||
+           MI.getOpcode() == X86::ADD64mi32 ||
+           MI.getOpcode() == X86::ADD64ri32 ||
+           MI.getOpcode() == X86::AND64i32 ||
+           MI.getOpcode() == X86::AND64mi32 ||
+           MI.getOpcode() == X86::AND64ri32 ||
+           MI.getOpcode() == X86::CMP64i32 ||
+           MI.getOpcode() == X86::CMP64mi32 ||
+           MI.getOpcode() == X86::CMP64ri32 ||
+           MI.getOpcode() == X86::IMUL64rmi32 ||
+           MI.getOpcode() == X86::IMUL64rri32 ||
+           MI.getOpcode() == X86::MOV64mi32 ||
+           MI.getOpcode() == X86::MOV64ri32 ||
+           MI.getOpcode() == X86::OR64i32 ||
+           MI.getOpcode() == X86::OR64mi32 ||
+           MI.getOpcode() == X86::OR64ri32 ||
+           MI.getOpcode() == X86::PUSH64i32 ||
+           MI.getOpcode() == X86::SBB64i32 ||
+           MI.getOpcode() == X86::SBB64mi32 ||
+           MI.getOpcode() == X86::SBB64ri32 ||
+           MI.getOpcode() == X86::SUB64i32 ||
+           MI.getOpcode() == X86::SUB64mi32 ||
+           MI.getOpcode() == X86::SUB64ri32 ||
+           MI.getOpcode() == X86::TEST64i32 ||
+           MI.getOpcode() == X86::TEST64mi32 ||
+           MI.getOpcode() == X86::TEST64ri32 ||
+           MI.getOpcode() == X86::XOR64i32 ||
+           MI.getOpcode() == X86::XOR64mi32 ||
+           MI.getOpcode() == X86::XOR64ri32)
         FixupKind = X86::reloc_signed_4byte;
       else
         FixupKind = getImmFixupKind(TSFlags);

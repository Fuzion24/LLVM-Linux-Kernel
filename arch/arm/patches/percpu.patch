From 588501907bb010ba8facd8cbfb49f6667370f685 Mon Sep 17 00:00:00 2001
From: Mark Charlebois <charlebm@gmail.com>
Date: Tue, 11 Mar 2014 10:43:45 -0700
Subject: [PATCH] arm, LLVMLinux: Remove use of named register for ARM percpu

The use of sp as a named register variable is not supported in clang and
the behavior they are working around in GCC may not even be present
in clang.

See commit 509eb76ebf97

Unfortunately, GCC doesn't treat a "memory" clobber on a non-volatile
asm block as a side-effect, and will happily re-order it before other
memory clobbers (including those in prempt_disable()) and cache the
value. This has been observed to break the cmpxchg logic in the slub
allocator, leading to livelock in kmem_cache_alloc in mainline kernels.

Because the GCC workaround causes numerous warnings, revert the change
until it can be verified that it is in fact an issue for clang.

Signed-off-by: Mark Charlebois <charlebm@gmail.com>
Signed-off-by: Behan Webster <behanw@converseincode.com>
---
 arch/arm/include/asm/compiler.h | 32 ++++++++++++++++++++++++++++++++
 arch/arm/include/asm/percpu.h   | 15 ++-------------
 2 files changed, 34 insertions(+), 13 deletions(-)

diff --git a/arch/arm/include/asm/compiler.h b/arch/arm/include/asm/compiler.h
index 8155db2..009eafa 100644
--- a/arch/arm/include/asm/compiler.h
+++ b/arch/arm/include/asm/compiler.h
@@ -11,5 +11,37 @@
  */
 #define __asmeq(x, y)  ".ifnc " x "," y " ; .err ; .endif\n\t"
 
+#if defined(CONFIG_SMP) && !defined(CONFIG_CPU_V6)
+/*
+ * Read TPIDRPRW.
+ * GCC requires a workaround as it does not treat a "memory" clobber on a
+ * non-volatile asm block as a side-effect.
+ * We want to allow caching the value, so for GCC avoid using volatile and
+ * instead use a fake stack read to hazard against barrier().
+ */
+#if defined(__clang__)
+static inline unsigned long read_TPIDRPRW(void)
+{
+	unsigned long off;
+
+	/*
+	 * Read TPIDRPRW.
+	 */
+	asm("mrc p15, 0, %0, c13, c0, 4" : "=r" (off) : : "memory");
+
+	return off;
+}
+#else
+static inline unsigned long read_TPIDRPRW(void)
+{
+	unsigned long off;
+	register unsigned long *sp asm ("sp");
+
+	asm("mrc p15, 0, %0, c13, c0, 4" : "=r" (off) : "Q" (*sp));
+
+	return off;
+}
+#endif
+#endif
 
 #endif /* __ASM_ARM_COMPILER_H */
diff --git a/arch/arm/include/asm/percpu.h b/arch/arm/include/asm/percpu.h
index 209e650..208c7e5 100644
--- a/arch/arm/include/asm/percpu.h
+++ b/arch/arm/include/asm/percpu.h
@@ -27,21 +27,10 @@ static inline void set_my_cpu_offset(unsigned long off)
 	asm volatile("mcr p15, 0, %0, c13, c0, 4" : : "r" (off) : "memory");
 }
 
-static inline unsigned long __my_cpu_offset(void)
-{
-	unsigned long off;
-	register unsigned long *sp asm ("sp");
+#include "asm/compiler.h"
 
-	/*
-	 * Read TPIDRPRW.
-	 * We want to allow caching the value, so avoid using volatile and
-	 * instead use a fake stack read to hazard against barrier().
-	 */
-	asm("mrc p15, 0, %0, c13, c0, 4" : "=r" (off) : "Q" (*sp));
+#define __my_cpu_offset read_TPIDRPRW()
 
-	return off;
-}
-#define __my_cpu_offset __my_cpu_offset()
 #else
 #define set_my_cpu_offset(x)	do {} while(0)
 
-- 
1.9.1

